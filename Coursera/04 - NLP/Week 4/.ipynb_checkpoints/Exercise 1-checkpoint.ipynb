{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zX4Kg8DUTKWO"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BOwsuGQQY9OL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PRnDnCW-Z7qv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n",
      "263\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "data=\"In the town of Athy one Jeremy Lanigan \\n Battered away til he hadnt a pound. \\nHis father died and made him a man again \\n Left him a farm and ten acres of ground. \\nHe gave a grand party for friends and relations \\nWho didnt forget him when come to the wall, \\nAnd if youll but listen Ill make your eyes glisten \\nOf the rows and the ructions of Lanigans Ball. \\nMyself to be sure got free invitation, \\nFor all the nice girls and boys I might ask, \\nAnd just in a minute both friends and relations \\nWere dancing round merry as bees round a cask. \\nJudy ODaly, that nice little milliner, \\nShe tipped me a wink for to give her a call, \\nAnd I soon arrived with Peggy McGilligan \\nJust in time for Lanigans Ball. \\nThere were lashings of punch and wine for the ladies, \\nPotatoes and cakes; there was bacon and tea, \\nThere were the Nolans, Dolans, OGradys \\nCourting the girls and dancing away. \\nSongs they went round as plenty as water, \\nThe harp that once sounded in Taras old hall,\\nSweet Nelly Gray and The Rat Catchers Daughter,\\nAll singing together at Lanigans Ball. \\nThey were doing all kinds of nonsensical polkas \\nAll round the room in a whirligig. \\nJulia and I, we banished their nonsense \\nAnd tipped them the twist of a reel and a jig. \\nAch mavrone, how the girls got all mad at me \\nDanced til youd think the ceiling would fall. \\nFor I spent three weeks at Brooks Academy \\nLearning new steps for Lanigans Ball. \\nThree long weeks I spent up in Dublin, \\nThree long weeks to learn nothing at all,\\n Three long weeks I spent up in Dublin, \\nLearning new steps for Lanigans Ball. \\nShe stepped out and I stepped in again, \\nI stepped out and she stepped in again, \\nShe stepped out and I stepped in again, \\nLearning new steps for Lanigans Ball. \\nBoys were all merry and the girls they were hearty \\nAnd danced all around in couples and groups, \\nTil an accident happened, young Terrance McCarthy \\nPut his right leg through miss Finnertys hoops. \\nPoor creature fainted and cried Meelia murther, \\nCalled for her brothers and gathered them all. \\nCarmody swore that hed go no further \\nTil he had satisfaction at Lanigans Ball. \\nIn the midst of the row miss Kerrigan fainted, \\nHer cheeks at the same time as red as a rose. \\nSome of the lads declared she was painted, \\nShe took a small drop too much, I suppose. \\nHer sweetheart, Ned Morgan, so powerful and able, \\nWhen he saw his fair colleen stretched out by the wall, \\nTore the left leg from under the table \\nAnd smashed all the Chaneys at Lanigans Ball. \\nBoys, oh boys, twas then there were runctions. \\nMyself got a lick from big Phelim McHugh. \\nI soon replied to his introduction \\nAnd kicked up a terrible hullabaloo. \\nOld Casey, the piper, was near being strangled. \\nThey squeezed up his pipes, bellows, chanters and all. \\nThe girls, in their ribbons, they got all entangled \\nAnd that put an end to Lanigans Ball.\"\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "soPGVheskaQP"
   },
   "outputs": [],
   "source": [
    "#Create ngrams for each line in  the corpus\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "#Create onehot encoding for labels\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pJtwVB2NbOAP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "66\n",
      "8\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index['in'])\n",
    "print(tokenizer.word_index['the'])\n",
    "print(tokenizer.word_index['town'])\n",
    "print(tokenizer.word_index['of'])\n",
    "print(tokenizer.word_index['athy'])\n",
    "print(tokenizer.word_index['one'])\n",
    "print(tokenizer.word_index['jeremy'])\n",
    "print(tokenizer.word_index['lanigan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "49Cv68JOakwv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  4  2 66  8 67 68 69]\n"
     ]
    }
   ],
   "source": [
    "print(xs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "iY-jwvfgbEF8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(ys[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wtzlUMYadhKt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0  0  4  2 66  8 67 68]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[5])\n",
    "print(ys[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "H4myRpB1c4Gg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 1, 'the': 2, 'a': 3, 'in': 4, 'all': 5, 'i': 6, 'for': 7, 'of': 8, 'lanigans': 9, 'ball': 10, 'were': 11, 'at': 12, 'to': 13, 'she': 14, 'stepped': 15, 'his': 16, 'girls': 17, 'as': 18, 'they': 19, 'til': 20, 'he': 21, 'again': 22, 'got': 23, 'boys': 24, 'round': 25, 'that': 26, 'her': 27, 'there': 28, 'three': 29, 'weeks': 30, 'up': 31, 'out': 32, 'him': 33, 'was': 34, 'spent': 35, 'learning': 36, 'new': 37, 'steps': 38, 'long': 39, 'away': 40, 'left': 41, 'friends': 42, 'relations': 43, 'when': 44, 'wall': 45, 'myself': 46, 'nice': 47, 'just': 48, 'dancing': 49, 'merry': 50, 'tipped': 51, 'me': 52, 'soon': 53, 'time': 54, 'old': 55, 'their': 56, 'them': 57, 'danced': 58, 'dublin': 59, 'an': 60, 'put': 61, 'leg': 62, 'miss': 63, 'fainted': 64, 'from': 65, 'town': 66, 'athy': 67, 'one': 68, 'jeremy': 69, 'lanigan': 70, 'battered': 71, 'hadnt': 72, 'pound': 73, 'father': 74, 'died': 75, 'made': 76, 'man': 77, 'farm': 78, 'ten': 79, 'acres': 80, 'ground': 81, 'gave': 82, 'grand': 83, 'party': 84, 'who': 85, 'didnt': 86, 'forget': 87, 'come': 88, 'if': 89, 'youll': 90, 'but': 91, 'listen': 92, 'ill': 93, 'make': 94, 'your': 95, 'eyes': 96, 'glisten': 97, 'rows': 98, 'ructions': 99, 'be': 100, 'sure': 101, 'free': 102, 'invitation': 103, 'might': 104, 'ask': 105, 'minute': 106, 'both': 107, 'bees': 108, 'cask': 109, 'judy': 110, 'odaly': 111, 'little': 112, 'milliner': 113, 'wink': 114, 'give': 115, 'call': 116, 'arrived': 117, 'with': 118, 'peggy': 119, 'mcgilligan': 120, 'lashings': 121, 'punch': 122, 'wine': 123, 'ladies': 124, 'potatoes': 125, 'cakes': 126, 'bacon': 127, 'tea': 128, 'nolans': 129, 'dolans': 130, 'ogradys': 131, 'courting': 132, 'songs': 133, 'went': 134, 'plenty': 135, 'water': 136, 'harp': 137, 'once': 138, 'sounded': 139, 'taras': 140, 'hall': 141, 'sweet': 142, 'nelly': 143, 'gray': 144, 'rat': 145, 'catchers': 146, 'daughter': 147, 'singing': 148, 'together': 149, 'doing': 150, 'kinds': 151, 'nonsensical': 152, 'polkas': 153, 'room': 154, 'whirligig': 155, 'julia': 156, 'we': 157, 'banished': 158, 'nonsense': 159, 'twist': 160, 'reel': 161, 'jig': 162, 'ach': 163, 'mavrone': 164, 'how': 165, 'mad': 166, 'youd': 167, 'think': 168, 'ceiling': 169, 'would': 170, 'fall': 171, 'brooks': 172, 'academy': 173, 'learn': 174, 'nothing': 175, 'hearty': 176, 'around': 177, 'couples': 178, 'groups': 179, 'accident': 180, 'happened': 181, 'young': 182, 'terrance': 183, 'mccarthy': 184, 'right': 185, 'through': 186, 'finnertys': 187, 'hoops': 188, 'poor': 189, 'creature': 190, 'cried': 191, 'meelia': 192, 'murther': 193, 'called': 194, 'brothers': 195, 'gathered': 196, 'carmody': 197, 'swore': 198, 'hed': 199, 'go': 200, 'no': 201, 'further': 202, 'had': 203, 'satisfaction': 204, 'midst': 205, 'row': 206, 'kerrigan': 207, 'cheeks': 208, 'same': 209, 'red': 210, 'rose': 211, 'some': 212, 'lads': 213, 'declared': 214, 'painted': 215, 'took': 216, 'small': 217, 'drop': 218, 'too': 219, 'much': 220, 'suppose': 221, 'sweetheart': 222, 'ned': 223, 'morgan': 224, 'so': 225, 'powerful': 226, 'able': 227, 'saw': 228, 'fair': 229, 'colleen': 230, 'stretched': 231, 'by': 232, 'tore': 233, 'under': 234, 'table': 235, 'smashed': 236, 'chaneys': 237, 'oh': 238, 'twas': 239, 'then': 240, 'runctions': 241, 'lick': 242, 'big': 243, 'phelim': 244, 'mchugh': 245, 'replied': 246, 'introduction': 247, 'kicked': 248, 'terrible': 249, 'hullabaloo': 250, 'casey': 251, 'piper': 252, 'near': 253, 'being': 254, 'strangled': 255, 'squeezed': 256, 'pipes': 257, 'bellows': 258, 'chanters': 259, 'ribbons': 260, 'entangled': 261, 'end': 262}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "w9vH8Y59ajYL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 453 samples\n",
      "Epoch 1/500\n",
      "453/453 [==============================] - 2s 5ms/sample - loss: 5.5707 - accuracy: 0.0066\n",
      "Epoch 2/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 5.5512 - accuracy: 0.0199\n",
      "Epoch 3/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 5.5101 - accuracy: 0.0243\n",
      "Epoch 4/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 5.3779 - accuracy: 0.0287\n",
      "Epoch 5/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 5.1713 - accuracy: 0.0508\n",
      "Epoch 6/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 5.0715 - accuracy: 0.0508\n",
      "Epoch 7/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 5.0288 - accuracy: 0.0508\n",
      "Epoch 8/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 4.9962 - accuracy: 0.0596\n",
      "Epoch 9/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 4.9612 - accuracy: 0.0574\n",
      "Epoch 10/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 4.9245 - accuracy: 0.0552\n",
      "Epoch 11/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 4.8808 - accuracy: 0.0640\n",
      "Epoch 12/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 4.8354 - accuracy: 0.0640\n",
      "Epoch 13/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 4.7841 - accuracy: 0.0684\n",
      "Epoch 14/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 4.7312 - accuracy: 0.0684\n",
      "Epoch 15/500\n",
      "453/453 [==============================] - 0s 120us/sample - loss: 4.6782 - accuracy: 0.0574\n",
      "Epoch 16/500\n",
      "453/453 [==============================] - 0s 197us/sample - loss: 4.6320 - accuracy: 0.0817\n",
      "Epoch 17/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 4.5911 - accuracy: 0.0684\n",
      "Epoch 18/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 4.5455 - accuracy: 0.0773\n",
      "Epoch 19/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 4.5047 - accuracy: 0.0795\n",
      "Epoch 20/500\n",
      "453/453 [==============================] - 0s 121us/sample - loss: 4.4685 - accuracy: 0.0883\n",
      "Epoch 21/500\n",
      "453/453 [==============================] - 0s 121us/sample - loss: 4.4296 - accuracy: 0.0905\n",
      "Epoch 22/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 4.3947 - accuracy: 0.1104\n",
      "Epoch 23/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 4.3657 - accuracy: 0.1060\n",
      "Epoch 24/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 4.3277 - accuracy: 0.1148\n",
      "Epoch 25/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 4.2955 - accuracy: 0.0949\n",
      "Epoch 26/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 4.2689 - accuracy: 0.0993\n",
      "Epoch 27/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 4.2531 - accuracy: 0.1192\n",
      "Epoch 28/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 4.2218 - accuracy: 0.1258\n",
      "Epoch 29/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 4.2341 - accuracy: 0.1325\n",
      "Epoch 30/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 4.1675 - accuracy: 0.1391\n",
      "Epoch 31/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 4.1284 - accuracy: 0.1435\n",
      "Epoch 32/500\n",
      "453/453 [==============================] - 0s 181us/sample - loss: 4.0983 - accuracy: 0.1501\n",
      "Epoch 33/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 4.0737 - accuracy: 0.1501\n",
      "Epoch 34/500\n",
      "453/453 [==============================] - 0s 131us/sample - loss: 4.0390 - accuracy: 0.1678\n",
      "Epoch 35/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 3.9952 - accuracy: 0.1744\n",
      "Epoch 36/500\n",
      "453/453 [==============================] - 0s 121us/sample - loss: 3.9666 - accuracy: 0.1854\n",
      "Epoch 37/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 3.9394 - accuracy: 0.1832\n",
      "Epoch 38/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 3.9039 - accuracy: 0.1898\n",
      "Epoch 39/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 3.8739 - accuracy: 0.1921\n",
      "Epoch 40/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 3.8432 - accuracy: 0.1943\n",
      "Epoch 41/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 3.8141 - accuracy: 0.1921\n",
      "Epoch 42/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 3.7808 - accuracy: 0.2009\n",
      "Epoch 43/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 3.7479 - accuracy: 0.2163\n",
      "Epoch 44/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 3.7148 - accuracy: 0.2141\n",
      "Epoch 45/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 3.6788 - accuracy: 0.2296\n",
      "Epoch 46/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 3.6469 - accuracy: 0.2362\n",
      "Epoch 47/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 3.6104 - accuracy: 0.2384\n",
      "Epoch 48/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 3.5808 - accuracy: 0.2450\n",
      "Epoch 49/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 3.5505 - accuracy: 0.2561\n",
      "Epoch 50/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 3.5207 - accuracy: 0.2561\n",
      "Epoch 51/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 3.4859 - accuracy: 0.2627\n",
      "Epoch 52/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 3.4599 - accuracy: 0.2826\n",
      "Epoch 53/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 3.4237 - accuracy: 0.2892\n",
      "Epoch 54/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 3.3878 - accuracy: 0.2826\n",
      "Epoch 55/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 3.3533 - accuracy: 0.2892\n",
      "Epoch 56/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 3.3199 - accuracy: 0.3024\n",
      "Epoch 57/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 3.2850 - accuracy: 0.3135\n",
      "Epoch 58/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 3.2539 - accuracy: 0.3135\n",
      "Epoch 59/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 3.2400 - accuracy: 0.3289\n",
      "Epoch 60/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 3.2115 - accuracy: 0.3157\n",
      "Epoch 61/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 3.1756 - accuracy: 0.3444\n",
      "Epoch 62/500\n",
      "453/453 [==============================] - 0s 121us/sample - loss: 3.1390 - accuracy: 0.3400\n",
      "Epoch 63/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 3.1037 - accuracy: 0.3687\n",
      "Epoch 64/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 3.0749 - accuracy: 0.3576\n",
      "Epoch 65/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 3.0488 - accuracy: 0.3753\n",
      "Epoch 66/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 3.0130 - accuracy: 0.3863\n",
      "Epoch 67/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 2.9897 - accuracy: 0.3951\n",
      "Epoch 68/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 2.9559 - accuracy: 0.3996\n",
      "Epoch 69/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 2.9451 - accuracy: 0.4062\n",
      "Epoch 70/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 2.9091 - accuracy: 0.4194\n",
      "Epoch 71/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 2.8730 - accuracy: 0.4260\n",
      "Epoch 72/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 2.8436 - accuracy: 0.4194\n",
      "Epoch 73/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 2.8313 - accuracy: 0.4283\n",
      "Epoch 74/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 2.8012 - accuracy: 0.4371\n",
      "Epoch 75/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 2.7741 - accuracy: 0.4547\n",
      "Epoch 76/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 2.7463 - accuracy: 0.4570\n",
      "Epoch 77/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 2.7163 - accuracy: 0.4614\n",
      "Epoch 78/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 124us/sample - loss: 2.6871 - accuracy: 0.4658\n",
      "Epoch 79/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 2.6598 - accuracy: 0.4879\n",
      "Epoch 80/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 2.6352 - accuracy: 0.5011\n",
      "Epoch 81/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 2.6060 - accuracy: 0.5077\n",
      "Epoch 82/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 2.6060 - accuracy: 0.5188\n",
      "Epoch 83/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 2.5708 - accuracy: 0.5143\n",
      "Epoch 84/500\n",
      "453/453 [==============================] - 0s 131us/sample - loss: 2.5359 - accuracy: 0.5342\n",
      "Epoch 85/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 2.5181 - accuracy: 0.5166\n",
      "Epoch 86/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 2.4908 - accuracy: 0.5320\n",
      "Epoch 87/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 2.4542 - accuracy: 0.5430\n",
      "Epoch 88/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 2.4268 - accuracy: 0.5717\n",
      "Epoch 89/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 2.4751 - accuracy: 0.5298\n",
      "Epoch 90/500\n",
      "453/453 [==============================] - 0s 121us/sample - loss: 2.4358 - accuracy: 0.5320\n",
      "Epoch 91/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 2.3853 - accuracy: 0.5585\n",
      "Epoch 92/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 2.3593 - accuracy: 0.5872\n",
      "Epoch 93/500\n",
      "453/453 [==============================] - 0s 131us/sample - loss: 2.3432 - accuracy: 0.5894\n",
      "Epoch 94/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 2.3126 - accuracy: 0.6004\n",
      "Epoch 95/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 2.2827 - accuracy: 0.6225\n",
      "Epoch 96/500\n",
      "453/453 [==============================] - 0s 122us/sample - loss: 2.2549 - accuracy: 0.6115\n",
      "Epoch 97/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 2.2140 - accuracy: 0.6291\n",
      "Epoch 98/500\n",
      "453/453 [==============================] - 0s 174us/sample - loss: 2.1890 - accuracy: 0.6313\n",
      "Epoch 99/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 2.1627 - accuracy: 0.6446\n",
      "Epoch 100/500\n",
      "453/453 [==============================] - 0s 161us/sample - loss: 2.1389 - accuracy: 0.6402\n",
      "Epoch 101/500\n",
      "453/453 [==============================] - 0s 167us/sample - loss: 2.1164 - accuracy: 0.6490\n",
      "Epoch 102/500\n",
      "453/453 [==============================] - 0s 185us/sample - loss: 2.1092 - accuracy: 0.6380\n",
      "Epoch 103/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 2.0950 - accuracy: 0.6269\n",
      "Epoch 104/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 2.0677 - accuracy: 0.6336\n",
      "Epoch 105/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 2.0430 - accuracy: 0.6556\n",
      "Epoch 106/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 2.0224 - accuracy: 0.6689\n",
      "Epoch 107/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 2.0111 - accuracy: 0.6600\n",
      "Epoch 108/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 1.9778 - accuracy: 0.6600\n",
      "Epoch 109/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.9562 - accuracy: 0.6711\n",
      "Epoch 110/500\n",
      "453/453 [==============================] - 0s 122us/sample - loss: 1.9314 - accuracy: 0.6711\n",
      "Epoch 111/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 1.9295 - accuracy: 0.6777\n",
      "Epoch 112/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 1.9043 - accuracy: 0.6954\n",
      "Epoch 113/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.8826 - accuracy: 0.6954\n",
      "Epoch 114/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 1.8561 - accuracy: 0.6998\n",
      "Epoch 115/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 1.8366 - accuracy: 0.7064\n",
      "Epoch 116/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 1.8224 - accuracy: 0.7064\n",
      "Epoch 117/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 1.8115 - accuracy: 0.7152\n",
      "Epoch 118/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 1.8065 - accuracy: 0.7174\n",
      "Epoch 119/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.7815 - accuracy: 0.7241\n",
      "Epoch 120/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.7477 - accuracy: 0.7373\n",
      "Epoch 121/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 1.7194 - accuracy: 0.7528\n",
      "Epoch 122/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.7071 - accuracy: 0.7506\n",
      "Epoch 123/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 1.7055 - accuracy: 0.7439\n",
      "Epoch 124/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 1.7375 - accuracy: 0.7351\n",
      "Epoch 125/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.7067 - accuracy: 0.7461\n",
      "Epoch 126/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 1.6990 - accuracy: 0.7307\n",
      "Epoch 127/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 1.6752 - accuracy: 0.7417\n",
      "Epoch 128/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 1.6322 - accuracy: 0.7594\n",
      "Epoch 129/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.5957 - accuracy: 0.7682\n",
      "Epoch 130/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.5687 - accuracy: 0.7837\n",
      "Epoch 131/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.5488 - accuracy: 0.7792\n",
      "Epoch 132/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.5298 - accuracy: 0.7837\n",
      "Epoch 133/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.5168 - accuracy: 0.7903\n",
      "Epoch 134/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 1.4953 - accuracy: 0.7925\n",
      "Epoch 135/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 1.4763 - accuracy: 0.8013\n",
      "Epoch 136/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 1.4655 - accuracy: 0.8013\n",
      "Epoch 137/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.4462 - accuracy: 0.8057\n",
      "Epoch 138/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.4249 - accuracy: 0.8079\n",
      "Epoch 139/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 1.4075 - accuracy: 0.8124\n",
      "Epoch 140/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 1.3903 - accuracy: 0.8124\n",
      "Epoch 141/500\n",
      "453/453 [==============================] - 0s 138us/sample - loss: 1.3800 - accuracy: 0.8146\n",
      "Epoch 142/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.3647 - accuracy: 0.8168\n",
      "Epoch 143/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 1.3510 - accuracy: 0.8124\n",
      "Epoch 144/500\n",
      "453/453 [==============================] - ETA: 0s - loss: 1.1822 - accuracy: 0.84 - 0s 124us/sample - loss: 1.3356 - accuracy: 0.8168\n",
      "Epoch 145/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 1.3222 - accuracy: 0.8212\n",
      "Epoch 146/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 1.3106 - accuracy: 0.8168\n",
      "Epoch 147/500\n",
      "453/453 [==============================] - 0s 131us/sample - loss: 1.2987 - accuracy: 0.8212\n",
      "Epoch 148/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 1.2828 - accuracy: 0.8278\n",
      "Epoch 149/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 1.2861 - accuracy: 0.8212\n",
      "Epoch 150/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 1.2737 - accuracy: 0.8190\n",
      "Epoch 151/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 1.2538 - accuracy: 0.8234\n",
      "Epoch 152/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 1.2428 - accuracy: 0.8366\n",
      "Epoch 153/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 1.2436 - accuracy: 0.8278\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 123us/sample - loss: 1.2519 - accuracy: 0.8278\n",
      "Epoch 155/500\n",
      "453/453 [==============================] - 0s 131us/sample - loss: 1.2428 - accuracy: 0.8234\n",
      "Epoch 156/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 1.2270 - accuracy: 0.8344\n",
      "Epoch 157/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 1.1972 - accuracy: 0.8300\n",
      "Epoch 158/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.1705 - accuracy: 0.8433\n",
      "Epoch 159/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 1.1581 - accuracy: 0.8411\n",
      "Epoch 160/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 1.1380 - accuracy: 0.8433\n",
      "Epoch 161/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 1.1267 - accuracy: 0.8477\n",
      "Epoch 162/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 1.1112 - accuracy: 0.8609\n",
      "Epoch 163/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 1.0994 - accuracy: 0.8631\n",
      "Epoch 164/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.0855 - accuracy: 0.8653\n",
      "Epoch 165/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.0702 - accuracy: 0.8653\n",
      "Epoch 166/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.0589 - accuracy: 0.8675\n",
      "Epoch 167/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 1.0466 - accuracy: 0.8653\n",
      "Epoch 168/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 1.0363 - accuracy: 0.8653\n",
      "Epoch 169/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 1.0263 - accuracy: 0.8698\n",
      "Epoch 170/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 1.0160 - accuracy: 0.8675\n",
      "Epoch 171/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 1.0063 - accuracy: 0.8698\n",
      "Epoch 172/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.9952 - accuracy: 0.8675\n",
      "Epoch 173/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.9855 - accuracy: 0.8720\n",
      "Epoch 174/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.9785 - accuracy: 0.8742\n",
      "Epoch 175/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.9761 - accuracy: 0.8764\n",
      "Epoch 176/500\n",
      "453/453 [==============================] - 0s 119us/sample - loss: 0.9775 - accuracy: 0.8609\n",
      "Epoch 177/500\n",
      "453/453 [==============================] - 0s 138us/sample - loss: 0.9626 - accuracy: 0.8675\n",
      "Epoch 178/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.9581 - accuracy: 0.8764\n",
      "Epoch 179/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.9515 - accuracy: 0.8675\n",
      "Epoch 180/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.9405 - accuracy: 0.8675\n",
      "Epoch 181/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 0.9326 - accuracy: 0.8720\n",
      "Epoch 182/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.9270 - accuracy: 0.8764\n",
      "Epoch 183/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.9174 - accuracy: 0.8742\n",
      "Epoch 184/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.9123 - accuracy: 0.8764\n",
      "Epoch 185/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.8973 - accuracy: 0.8808\n",
      "Epoch 186/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 0.8839 - accuracy: 0.8764\n",
      "Epoch 187/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.8737 - accuracy: 0.8786\n",
      "Epoch 188/500\n",
      "453/453 [==============================] - 0s 149us/sample - loss: 0.8597 - accuracy: 0.8852\n",
      "Epoch 189/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.8499 - accuracy: 0.8808\n",
      "Epoch 190/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.8404 - accuracy: 0.8852\n",
      "Epoch 191/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 0.8308 - accuracy: 0.8896\n",
      "Epoch 192/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.8212 - accuracy: 0.8852\n",
      "Epoch 193/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.8119 - accuracy: 0.8874\n",
      "Epoch 194/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.8037 - accuracy: 0.8874\n",
      "Epoch 195/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.7949 - accuracy: 0.8918\n",
      "Epoch 196/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.7857 - accuracy: 0.8940\n",
      "Epoch 197/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.7787 - accuracy: 0.8962\n",
      "Epoch 198/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.7714 - accuracy: 0.8940\n",
      "Epoch 199/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.7654 - accuracy: 0.8985\n",
      "Epoch 200/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 0.7601 - accuracy: 0.9007\n",
      "Epoch 201/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.7677 - accuracy: 0.8852\n",
      "Epoch 202/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.7573 - accuracy: 0.8940\n",
      "Epoch 203/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.8108 - accuracy: 0.8830\n",
      "Epoch 204/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.8459 - accuracy: 0.8631\n",
      "Epoch 205/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 0.8030 - accuracy: 0.8786\n",
      "Epoch 206/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.8023 - accuracy: 0.8764\n",
      "Epoch 207/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.7567 - accuracy: 0.8940\n",
      "Epoch 208/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.7239 - accuracy: 0.9051\n",
      "Epoch 209/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.7069 - accuracy: 0.9073\n",
      "Epoch 210/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.6955 - accuracy: 0.9051\n",
      "Epoch 211/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.6886 - accuracy: 0.9073\n",
      "Epoch 212/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.6796 - accuracy: 0.9095\n",
      "Epoch 213/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.6723 - accuracy: 0.9073\n",
      "Epoch 214/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.6662 - accuracy: 0.9183\n",
      "Epoch 215/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.6589 - accuracy: 0.9183\n",
      "Epoch 216/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 0.6516 - accuracy: 0.9183\n",
      "Epoch 217/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.6449 - accuracy: 0.9205\n",
      "Epoch 218/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.6395 - accuracy: 0.9205\n",
      "Epoch 219/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.6346 - accuracy: 0.9205\n",
      "Epoch 220/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.6277 - accuracy: 0.9249\n",
      "Epoch 221/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 0.6234 - accuracy: 0.9183\n",
      "Epoch 222/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.6171 - accuracy: 0.9183\n",
      "Epoch 223/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.6104 - accuracy: 0.9249\n",
      "Epoch 224/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.6058 - accuracy: 0.9249\n",
      "Epoch 225/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.5987 - accuracy: 0.9249\n",
      "Epoch 226/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 0.5934 - accuracy: 0.9272\n",
      "Epoch 227/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.5881 - accuracy: 0.9249\n",
      "Epoch 228/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.5829 - accuracy: 0.9272\n",
      "Epoch 229/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.5771 - accuracy: 0.9316\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 125us/sample - loss: 0.5731 - accuracy: 0.9360\n",
      "Epoch 231/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.5671 - accuracy: 0.9316\n",
      "Epoch 232/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.5634 - accuracy: 0.9338\n",
      "Epoch 233/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.5572 - accuracy: 0.9272\n",
      "Epoch 234/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.5540 - accuracy: 0.9338\n",
      "Epoch 235/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 0.5520 - accuracy: 0.9316\n",
      "Epoch 236/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.5517 - accuracy: 0.9360\n",
      "Epoch 237/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.5458 - accuracy: 0.9360\n",
      "Epoch 238/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.5388 - accuracy: 0.9360\n",
      "Epoch 239/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.5305 - accuracy: 0.9382\n",
      "Epoch 240/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.5258 - accuracy: 0.9404\n",
      "Epoch 241/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.5235 - accuracy: 0.9426\n",
      "Epoch 242/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.5214 - accuracy: 0.9360\n",
      "Epoch 243/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.5217 - accuracy: 0.9404\n",
      "Epoch 244/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.5200 - accuracy: 0.9382\n",
      "Epoch 245/500\n",
      "453/453 [==============================] - 0s 140us/sample - loss: 0.5276 - accuracy: 0.9426\n",
      "Epoch 246/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 0.5132 - accuracy: 0.9404\n",
      "Epoch 247/500\n",
      "453/453 [==============================] - 0s 159us/sample - loss: 0.5370 - accuracy: 0.9360\n",
      "Epoch 248/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.5569 - accuracy: 0.9294\n",
      "Epoch 249/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.5726 - accuracy: 0.9272\n",
      "Epoch 250/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 0.5292 - accuracy: 0.9338\n",
      "Epoch 251/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.5245 - accuracy: 0.9316\n",
      "Epoch 252/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.5173 - accuracy: 0.9404\n",
      "Epoch 253/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.5251 - accuracy: 0.9338\n",
      "Epoch 254/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.5156 - accuracy: 0.9338\n",
      "Epoch 255/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.5050 - accuracy: 0.9360\n",
      "Epoch 256/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 0.4934 - accuracy: 0.9404\n",
      "Epoch 257/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.4861 - accuracy: 0.9404\n",
      "Epoch 258/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.4766 - accuracy: 0.9426\n",
      "Epoch 259/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.4739 - accuracy: 0.9404\n",
      "Epoch 260/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.4670 - accuracy: 0.9448\n",
      "Epoch 261/500\n",
      "453/453 [==============================] - 0s 115us/sample - loss: 0.4561 - accuracy: 0.9470\n",
      "Epoch 262/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.4520 - accuracy: 0.9470\n",
      "Epoch 263/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.4459 - accuracy: 0.9492\n",
      "Epoch 264/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.4389 - accuracy: 0.9470\n",
      "Epoch 265/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.4370 - accuracy: 0.9470\n",
      "Epoch 266/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.4303 - accuracy: 0.9426\n",
      "Epoch 267/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 0.4267 - accuracy: 0.9470\n",
      "Epoch 268/500\n",
      "453/453 [==============================] - 0s 190us/sample - loss: 0.4224 - accuracy: 0.9426\n",
      "Epoch 269/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.4190 - accuracy: 0.9448\n",
      "Epoch 270/500\n",
      "453/453 [==============================] - 0s 140us/sample - loss: 0.4143 - accuracy: 0.9470\n",
      "Epoch 271/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 0.4155 - accuracy: 0.9492\n",
      "Epoch 272/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.4103 - accuracy: 0.9426\n",
      "Epoch 273/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.4044 - accuracy: 0.9448\n",
      "Epoch 274/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.4002 - accuracy: 0.9492\n",
      "Epoch 275/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 0.3975 - accuracy: 0.9470\n",
      "Epoch 276/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.3939 - accuracy: 0.9448\n",
      "Epoch 277/500\n",
      "453/453 [==============================] - 0s 148us/sample - loss: 0.3901 - accuracy: 0.9448\n",
      "Epoch 278/500\n",
      "453/453 [==============================] - 0s 131us/sample - loss: 0.3881 - accuracy: 0.9448\n",
      "Epoch 279/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 0.3845 - accuracy: 0.9426\n",
      "Epoch 280/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.3810 - accuracy: 0.9470\n",
      "Epoch 281/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.3780 - accuracy: 0.9492\n",
      "Epoch 282/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.3750 - accuracy: 0.9492\n",
      "Epoch 283/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.3723 - accuracy: 0.9492\n",
      "Epoch 284/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.3719 - accuracy: 0.9470\n",
      "Epoch 285/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 0.3671 - accuracy: 0.9492\n",
      "Epoch 286/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.3643 - accuracy: 0.9492\n",
      "Epoch 287/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.3616 - accuracy: 0.9448\n",
      "Epoch 288/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.3585 - accuracy: 0.9492\n",
      "Epoch 289/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.3554 - accuracy: 0.9448\n",
      "Epoch 290/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.3516 - accuracy: 0.9514\n",
      "Epoch 291/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.3487 - accuracy: 0.9492\n",
      "Epoch 292/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.3456 - accuracy: 0.9514\n",
      "Epoch 293/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.3437 - accuracy: 0.9448\n",
      "Epoch 294/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.3420 - accuracy: 0.9492\n",
      "Epoch 295/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.3390 - accuracy: 0.9492\n",
      "Epoch 296/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.3372 - accuracy: 0.9470\n",
      "Epoch 297/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.3378 - accuracy: 0.9492\n",
      "Epoch 298/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.3338 - accuracy: 0.9470\n",
      "Epoch 299/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.3322 - accuracy: 0.9470\n",
      "Epoch 300/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.3296 - accuracy: 0.9492\n",
      "Epoch 301/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.3262 - accuracy: 0.9470\n",
      "Epoch 302/500\n",
      "453/453 [==============================] - 0s 151us/sample - loss: 0.3234 - accuracy: 0.9492\n",
      "Epoch 303/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.3212 - accuracy: 0.9514\n",
      "Epoch 304/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.3188 - accuracy: 0.9470\n",
      "Epoch 305/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.3186 - accuracy: 0.9470\n",
      "Epoch 306/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 134us/sample - loss: 0.3154 - accuracy: 0.9514\n",
      "Epoch 307/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.3133 - accuracy: 0.9492\n",
      "Epoch 308/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.3110 - accuracy: 0.9492\n",
      "Epoch 309/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.3089 - accuracy: 0.9492\n",
      "Epoch 310/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.3057 - accuracy: 0.9470\n",
      "Epoch 311/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 0.3036 - accuracy: 0.9514\n",
      "Epoch 312/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 0.3014 - accuracy: 0.9492\n",
      "Epoch 313/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.3003 - accuracy: 0.9492\n",
      "Epoch 314/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2985 - accuracy: 0.9470\n",
      "Epoch 315/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.2957 - accuracy: 0.9492\n",
      "Epoch 316/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.2932 - accuracy: 0.9514\n",
      "Epoch 317/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 0.2917 - accuracy: 0.9514\n",
      "Epoch 318/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2937 - accuracy: 0.9470\n",
      "Epoch 319/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.2909 - accuracy: 0.9492\n",
      "Epoch 320/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.2886 - accuracy: 0.9492\n",
      "Epoch 321/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.2857 - accuracy: 0.9514\n",
      "Epoch 322/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2847 - accuracy: 0.9470\n",
      "Epoch 323/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.2821 - accuracy: 0.9470\n",
      "Epoch 324/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.2812 - accuracy: 0.9514\n",
      "Epoch 325/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 0.2786 - accuracy: 0.9492\n",
      "Epoch 326/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2760 - accuracy: 0.9492\n",
      "Epoch 327/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.2743 - accuracy: 0.9514\n",
      "Epoch 328/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 0.2727 - accuracy: 0.9514\n",
      "Epoch 329/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2705 - accuracy: 0.9514\n",
      "Epoch 330/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.2695 - accuracy: 0.9470\n",
      "Epoch 331/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.2677 - accuracy: 0.9514\n",
      "Epoch 332/500\n",
      "453/453 [==============================] - 0s 138us/sample - loss: 0.2665 - accuracy: 0.9492\n",
      "Epoch 333/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.2642 - accuracy: 0.9492\n",
      "Epoch 334/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2633 - accuracy: 0.9514\n",
      "Epoch 335/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.2621 - accuracy: 0.9514\n",
      "Epoch 336/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.2602 - accuracy: 0.9470\n",
      "Epoch 337/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.2583 - accuracy: 0.9492\n",
      "Epoch 338/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.2571 - accuracy: 0.9536\n",
      "Epoch 339/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.2548 - accuracy: 0.9492\n",
      "Epoch 340/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 0.2543 - accuracy: 0.9470\n",
      "Epoch 341/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.2523 - accuracy: 0.9492\n",
      "Epoch 342/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2515 - accuracy: 0.9470\n",
      "Epoch 343/500\n",
      "453/453 [==============================] - 0s 155us/sample - loss: 0.2501 - accuracy: 0.9492\n",
      "Epoch 344/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2490 - accuracy: 0.9492\n",
      "Epoch 345/500\n",
      "453/453 [==============================] - 0s 162us/sample - loss: 0.2469 - accuracy: 0.9514\n",
      "Epoch 346/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.2453 - accuracy: 0.9492\n",
      "Epoch 347/500\n",
      "453/453 [==============================] - 0s 169us/sample - loss: 0.2436 - accuracy: 0.9492\n",
      "Epoch 348/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.2418 - accuracy: 0.9514\n",
      "Epoch 349/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.2400 - accuracy: 0.9492\n",
      "Epoch 350/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.2390 - accuracy: 0.9470\n",
      "Epoch 351/500\n",
      "453/453 [==============================] - 0s 173us/sample - loss: 0.2375 - accuracy: 0.9492\n",
      "Epoch 352/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.2366 - accuracy: 0.9492\n",
      "Epoch 353/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.2348 - accuracy: 0.9536\n",
      "Epoch 354/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.2359 - accuracy: 0.9514\n",
      "Epoch 355/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.2338 - accuracy: 0.9492\n",
      "Epoch 356/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.2334 - accuracy: 0.9470\n",
      "Epoch 357/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2315 - accuracy: 0.9492\n",
      "Epoch 358/500\n",
      "453/453 [==============================] - 0s 160us/sample - loss: 0.2301 - accuracy: 0.9514\n",
      "Epoch 359/500\n",
      "453/453 [==============================] - 0s 169us/sample - loss: 0.2348 - accuracy: 0.9470\n",
      "Epoch 360/500\n",
      "453/453 [==============================] - 0s 155us/sample - loss: 0.2472 - accuracy: 0.9492\n",
      "Epoch 361/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 0.3734 - accuracy: 0.9183\n",
      "Epoch 362/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 0.3780 - accuracy: 0.9161\n",
      "Epoch 363/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.3321 - accuracy: 0.9294\n",
      "Epoch 364/500\n",
      "453/453 [==============================] - 0s 156us/sample - loss: 0.3326 - accuracy: 0.9117\n",
      "Epoch 365/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.3600 - accuracy: 0.9073\n",
      "Epoch 366/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.3387 - accuracy: 0.9338\n",
      "Epoch 367/500\n",
      "453/453 [==============================] - 0s 170us/sample - loss: 0.2839 - accuracy: 0.9448\n",
      "Epoch 368/500\n",
      "453/453 [==============================] - 0s 152us/sample - loss: 0.2667 - accuracy: 0.9426\n",
      "Epoch 369/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.2574 - accuracy: 0.9448\n",
      "Epoch 370/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.2448 - accuracy: 0.9426\n",
      "Epoch 371/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 0.2366 - accuracy: 0.9492\n",
      "Epoch 372/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2284 - accuracy: 0.9492\n",
      "Epoch 373/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.2244 - accuracy: 0.9448\n",
      "Epoch 374/500\n",
      "453/453 [==============================] - 0s 150us/sample - loss: 0.2211 - accuracy: 0.9470\n",
      "Epoch 375/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2201 - accuracy: 0.9448\n",
      "Epoch 376/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.2172 - accuracy: 0.9470\n",
      "Epoch 377/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.2151 - accuracy: 0.9470\n",
      "Epoch 378/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2139 - accuracy: 0.9470\n",
      "Epoch 379/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.2119 - accuracy: 0.9426\n",
      "Epoch 380/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.2097 - accuracy: 0.9514\n",
      "Epoch 381/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.2082 - accuracy: 0.9470\n",
      "Epoch 382/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 131us/sample - loss: 0.2069 - accuracy: 0.9492\n",
      "Epoch 383/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.2054 - accuracy: 0.9514\n",
      "Epoch 384/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.2039 - accuracy: 0.9492\n",
      "Epoch 385/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.2022 - accuracy: 0.9492\n",
      "Epoch 386/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.2013 - accuracy: 0.9514\n",
      "Epoch 387/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.2000 - accuracy: 0.9514\n",
      "Epoch 388/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.1994 - accuracy: 0.9492\n",
      "Epoch 389/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1982 - accuracy: 0.9492\n",
      "Epoch 390/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 0.1982 - accuracy: 0.9492\n",
      "Epoch 391/500\n",
      "453/453 [==============================] - 0s 123us/sample - loss: 0.1968 - accuracy: 0.9492\n",
      "Epoch 392/500\n",
      "453/453 [==============================] - ETA: 0s - loss: 0.1856 - accuracy: 0.96 - 0s 127us/sample - loss: 0.1963 - accuracy: 0.9492\n",
      "Epoch 393/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.1953 - accuracy: 0.9470\n",
      "Epoch 394/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1946 - accuracy: 0.9536\n",
      "Epoch 395/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1945 - accuracy: 0.9448\n",
      "Epoch 396/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 0.1925 - accuracy: 0.9448\n",
      "Epoch 397/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1912 - accuracy: 0.9492\n",
      "Epoch 398/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1900 - accuracy: 0.9492\n",
      "Epoch 399/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.1892 - accuracy: 0.9470\n",
      "Epoch 400/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1884 - accuracy: 0.9470\n",
      "Epoch 401/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1881 - accuracy: 0.9492\n",
      "Epoch 402/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1873 - accuracy: 0.9492\n",
      "Epoch 403/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1864 - accuracy: 0.9536\n",
      "Epoch 404/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1865 - accuracy: 0.9470\n",
      "Epoch 405/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.1855 - accuracy: 0.9492\n",
      "Epoch 406/500\n",
      "453/453 [==============================] - 0s 135us/sample - loss: 0.1842 - accuracy: 0.9470\n",
      "Epoch 407/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1829 - accuracy: 0.9492\n",
      "Epoch 408/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1818 - accuracy: 0.9514\n",
      "Epoch 409/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1817 - accuracy: 0.9492\n",
      "Epoch 410/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.1809 - accuracy: 0.9492\n",
      "Epoch 411/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.1800 - accuracy: 0.9470\n",
      "Epoch 412/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.1795 - accuracy: 0.9492\n",
      "Epoch 413/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.1785 - accuracy: 0.9514\n",
      "Epoch 414/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.1775 - accuracy: 0.9492\n",
      "Epoch 415/500\n",
      "453/453 [==============================] - 0s 145us/sample - loss: 0.1774 - accuracy: 0.9514\n",
      "Epoch 416/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.1764 - accuracy: 0.9514\n",
      "Epoch 417/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1757 - accuracy: 0.9492\n",
      "Epoch 418/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1752 - accuracy: 0.9514\n",
      "Epoch 419/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1745 - accuracy: 0.9470\n",
      "Epoch 420/500\n",
      "453/453 [==============================] - 0s 166us/sample - loss: 0.1735 - accuracy: 0.9514\n",
      "Epoch 421/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.1721 - accuracy: 0.9536\n",
      "Epoch 422/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1722 - accuracy: 0.9492\n",
      "Epoch 423/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.1709 - accuracy: 0.9536\n",
      "Epoch 424/500\n",
      "453/453 [==============================] - 0s 163us/sample - loss: 0.1705 - accuracy: 0.9514\n",
      "Epoch 425/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.1699 - accuracy: 0.9470\n",
      "Epoch 426/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1702 - accuracy: 0.9492\n",
      "Epoch 427/500\n",
      "453/453 [==============================] - 0s 133us/sample - loss: 0.1694 - accuracy: 0.9536\n",
      "Epoch 428/500\n",
      "453/453 [==============================] - 0s 165us/sample - loss: 0.1682 - accuracy: 0.9514\n",
      "Epoch 429/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1675 - accuracy: 0.9514\n",
      "Epoch 430/500\n",
      "453/453 [==============================] - 0s 158us/sample - loss: 0.1669 - accuracy: 0.9514\n",
      "Epoch 431/500\n",
      "453/453 [==============================] - 0s 149us/sample - loss: 0.1661 - accuracy: 0.9492\n",
      "Epoch 432/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.1656 - accuracy: 0.9514\n",
      "Epoch 433/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1662 - accuracy: 0.9492\n",
      "Epoch 434/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1652 - accuracy: 0.9492\n",
      "Epoch 435/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.1641 - accuracy: 0.9514\n",
      "Epoch 436/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.1640 - accuracy: 0.9492\n",
      "Epoch 437/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1630 - accuracy: 0.9514\n",
      "Epoch 438/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.1616 - accuracy: 0.9558\n",
      "Epoch 439/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1616 - accuracy: 0.9536\n",
      "Epoch 440/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1604 - accuracy: 0.9558\n",
      "Epoch 441/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1598 - accuracy: 0.9514\n",
      "Epoch 442/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.1606 - accuracy: 0.9514\n",
      "Epoch 443/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.1596 - accuracy: 0.9514\n",
      "Epoch 444/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1602 - accuracy: 0.9514\n",
      "Epoch 445/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.1594 - accuracy: 0.9514\n",
      "Epoch 446/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1587 - accuracy: 0.9448\n",
      "Epoch 447/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.1583 - accuracy: 0.9470\n",
      "Epoch 448/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1573 - accuracy: 0.9492\n",
      "Epoch 449/500\n",
      "453/453 [==============================] - 0s 141us/sample - loss: 0.1568 - accuracy: 0.9514\n",
      "Epoch 450/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1560 - accuracy: 0.9514\n",
      "Epoch 451/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.1550 - accuracy: 0.9536\n",
      "Epoch 452/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.1543 - accuracy: 0.9514\n",
      "Epoch 453/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.1538 - accuracy: 0.9536\n",
      "Epoch 454/500\n",
      "453/453 [==============================] - 0s 143us/sample - loss: 0.1544 - accuracy: 0.9492\n",
      "Epoch 455/500\n",
      "453/453 [==============================] - 0s 154us/sample - loss: 0.1556 - accuracy: 0.9536\n",
      "Epoch 456/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1536 - accuracy: 0.9536\n",
      "Epoch 457/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.1545 - accuracy: 0.9536\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1536 - accuracy: 0.9536\n",
      "Epoch 459/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1522 - accuracy: 0.9514\n",
      "Epoch 460/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.1515 - accuracy: 0.9536\n",
      "Epoch 461/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.1508 - accuracy: 0.9514\n",
      "Epoch 462/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.1497 - accuracy: 0.9492\n",
      "Epoch 463/500\n",
      "453/453 [==============================] - 0s 139us/sample - loss: 0.1533 - accuracy: 0.9536\n",
      "Epoch 464/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1522 - accuracy: 0.9536\n",
      "Epoch 465/500\n",
      "453/453 [==============================] - 0s 124us/sample - loss: 0.1566 - accuracy: 0.9492\n",
      "Epoch 466/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.1557 - accuracy: 0.9558\n",
      "Epoch 467/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1523 - accuracy: 0.9514\n",
      "Epoch 468/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.1544 - accuracy: 0.9492\n",
      "Epoch 469/500\n",
      "453/453 [==============================] - 0s 137us/sample - loss: 0.1705 - accuracy: 0.9492\n",
      "Epoch 470/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.2103 - accuracy: 0.9382\n",
      "Epoch 471/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1835 - accuracy: 0.9536\n",
      "Epoch 472/500\n",
      "453/453 [==============================] - 0s 146us/sample - loss: 0.1818 - accuracy: 0.9382\n",
      "Epoch 473/500\n",
      "453/453 [==============================] - 0s 138us/sample - loss: 0.2434 - accuracy: 0.9316\n",
      "Epoch 474/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2897 - accuracy: 0.9183\n",
      "Epoch 475/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.2788 - accuracy: 0.9205\n",
      "Epoch 476/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.2613 - accuracy: 0.9294\n",
      "Epoch 477/500\n",
      "453/453 [==============================] - 0s 134us/sample - loss: 0.2274 - accuracy: 0.9338\n",
      "Epoch 478/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.2070 - accuracy: 0.9426\n",
      "Epoch 479/500\n",
      "453/453 [==============================] - 0s 147us/sample - loss: 0.1912 - accuracy: 0.9492\n",
      "Epoch 480/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1787 - accuracy: 0.9492\n",
      "Epoch 481/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1726 - accuracy: 0.9448\n",
      "Epoch 482/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1674 - accuracy: 0.9514\n",
      "Epoch 483/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1615 - accuracy: 0.9492\n",
      "Epoch 484/500\n",
      "453/453 [==============================] - 0s 125us/sample - loss: 0.1668 - accuracy: 0.9514\n",
      "Epoch 485/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1593 - accuracy: 0.9492\n",
      "Epoch 486/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1572 - accuracy: 0.9514\n",
      "Epoch 487/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1564 - accuracy: 0.9514\n",
      "Epoch 488/500\n",
      "453/453 [==============================] - 0s 128us/sample - loss: 0.1538 - accuracy: 0.9514\n",
      "Epoch 489/500\n",
      "453/453 [==============================] - 0s 142us/sample - loss: 0.1519 - accuracy: 0.9470\n",
      "Epoch 490/500\n",
      "453/453 [==============================] - 0s 147us/sample - loss: 0.1507 - accuracy: 0.9470\n",
      "Epoch 491/500\n",
      "453/453 [==============================] - 0s 136us/sample - loss: 0.1492 - accuracy: 0.9492\n",
      "Epoch 492/500\n",
      "453/453 [==============================] - 0s 131us/sample - loss: 0.1482 - accuracy: 0.9492\n",
      "Epoch 493/500\n",
      "453/453 [==============================] - 0s 127us/sample - loss: 0.1469 - accuracy: 0.9470\n",
      "Epoch 494/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1469 - accuracy: 0.9514\n",
      "Epoch 495/500\n",
      "453/453 [==============================] - 0s 132us/sample - loss: 0.1465 - accuracy: 0.9492\n",
      "Epoch 496/500\n",
      "453/453 [==============================] - 0s 126us/sample - loss: 0.1461 - accuracy: 0.9470\n",
      "Epoch 497/500\n",
      "453/453 [==============================] - 0s 130us/sample - loss: 0.1457 - accuracy: 0.9514\n",
      "Epoch 498/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 0.1446 - accuracy: 0.9514\n",
      "Epoch 499/500\n",
      "453/453 [==============================] - 0s 129us/sample - loss: 0.1433 - accuracy: 0.9514\n",
      "Epoch 500/500\n",
      "453/453 [==============================] - 0s 108us/sample - loss: 0.1424 - accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "  model = Sequential()\n",
    "  model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "  model.add(Bidirectional(LSTM(20)))\n",
    "  model.add(Dense(total_words, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "  history = model.fit(xs, ys, epochs=500, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3YXGelKThoTT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "poeprYK8h-c7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 10, 64)            16832     \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 40)                13600     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 263)               10783     \n",
      "=================================================================\n",
      "Total params: 41,215\n",
      "Trainable params: 41,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Tensor(\"embedding/Identity:0\", shape=(None, 10, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')\n",
    "model.summary()\n",
    "elayer = model.layers[0]\n",
    "elayer_weights = np.array(elayer.get_weights())\n",
    "print(elayer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "6Vc6PHgxa6Hm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laurence went to dublin his further further stretched out by the wall wall ground wall ground entangled entangled relations ground youd swore relations youd ground twas eyes swore girls were squeezed fall father father youll morgan chaneys ball again squeezed plenty as stretched forget oh friends and relations hearty relations twas eyes ground swore girls of soon eyes went come learn how as time a whirligig and rose rose painted relations relations swore relations girls were were relations girls forget how were were hearty hearty swore girls of runctions hearty ground twas eyes of relations hearty ground youd swore girls were squeezed glisten youll\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Laurence went to dublin\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Course 3 - Week 4 - Lesson 1 - Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
